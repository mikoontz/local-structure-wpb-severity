---
bibliography: ../docs_carpentry/local-structure-wpb-severity.bib
csl: ../docs_carpentry/ecological-applications.csl

params:
  date_generated: !r format(Sys.Date(), "%B %d, %Y")
  
geometry: margin=1in
header-includes:
  - \usepackage[left]{lineno}
  - \linenumbers
  - \usepackage{setspace}
  - \doublespacing
  - \DeclareUnicodeCharacter{200E}{}
  - \usepackage{caption}
  - \captionsetup[figure]{labelformat=empty}
  - \captionsetup[table]{labelformat=empty}

output: pdf_document
---

```{r setup, include = FALSE, echo = FALSE}
knitr::opts_chunk$set(echo = FALSE, include = FALSE)
```

```{r libraries}
library(tidyverse)
library(pander)
library(captioner)
```

```{r captions}
fig_nums <- captioner(prefix = "Figure")
table_nums <- captioner(prefix = "Table")
eq_nums <- captioner(prefix = "Equation")
```

```{r source_necessary_scripts}
# Information about correspondence of tree top detection algorithms with ground data
algorithm_stats <- read_rds(here::here("analyses/analyses_output/algorithm_stats.rds"))
best_algorithm_deets <- algorithm_stats$best_algorithm_deets
algorithm_details <- algorithm_stats$algorithm_details
algorithm_summary <- algorithm_stats$algorithm_summary

d <- read_csv(here::here("data/data_output/formatted-ground-data.csv"))
```

```{r ground_data_deets}
pipo_pct_of_all_dead <-
  d %>%
  dplyr::filter(is.na(year_fall), !is.na(year_dead)) %>%
  group_by(species) %>%
  summarize(n = n(),
            prop_of_all_dead = n() / nrow(.),
            print_prop = round(prop_of_all_dead * 100, digits = 2)) %>%
  dplyr::filter(species == "PIPO") %>%
  pull(print_prop)

cade_pct_of_all_dead <-
  d %>%
  dplyr::filter(is.na(year_fall), !is.na(year_dead)) %>%
  group_by(species) %>%
  summarize(n = n(),
            prop_of_all_dead = n() / nrow(.),
            print_prop = round(prop_of_all_dead * 100, digits = 2)) %>%
  dplyr::filter(species == "CADE") %>%
  pull(print_prop)
```

```{r ground_tree_summary}
ground_tree_summary <- readr::read_csv(here::here("analyses/analyses_output/ground-tree-summary.csv"))

ground_tree_summary_print <-
  ground_tree_summary %>% 
  summarize(mean_total_count = mean(total_tree_count),
            mean_short_count = mean(tree_count_below_15m),
            mean_tall_count = mean(tree_count_above_15m),
            mean_nn1 = mean(nn_1_mean),
            mean_nn2 = mean(nn_2_mean),
            mean_nn3 = mean(nn_3_mean),
            mean_short_height = mean(height_lwr_25),
            mean_height = mean(height_mean),
            mean_tall_height = mean(height_upr_25))

```


```{r classifier_stats}
classifier_stats <- read_csv(here::here("analyses/analyses_output/classification-summary-stats.csv"))
```

```{r hand_classified_crowns}
hand_classified_crowns <- read_csv(here::here("data/data_output/classified/hand-classified/hand-classified-crowns.csv")) %>% 
  dplyr::mutate(site = substr(treeID, start = 1, stop = 9))
```


```{r feet_to_meters}
# 3000 = 914
# 4000 = 1219
# 5000 = 1524
# 6000 = 1829
# 7000 = 2134
```

## Supplemental Methods

Date report generated: `r params$date_generated`

### Instrumentation

Imagery was captured using a DJI Zenmuse X3 RGB camera [@dji2015] and a Micasense RedEdge3 5-band multispectral camera [@micasense2015].
We mounted both of these instruments simultaneously on a DJI Matrice 100 aircraft [@dji2015a] using the DJI 3-axis stabilized gimbal for the Zenmuse X3 camera and a Micasense angled fixed mount for the RedEdge3 camera.
The gimbal and the angled fixed mount ensured both instruments were nadir-facing during image capture.
Just prior to or after image capture at each site, we calibrated the RedEdge3 camera by taking an image of a calibration panel on the ground in full sun with known reflectance values for each of the 5 narrow bands (`r table_nums(name = "table-rededge-specs", display = "cite")`).

```{r}
table_nums(name = "table-rededge-specs", "Reflectance sensitivity of the Micasense Rededge3 camera.
The calibration panel value represents the reflectance of the calibration panel for the given wavelength.")
```

```{r rededge_deets, echo = FALSE, include = TRUE, results = 'asis'}
rededge_print <- 
  tibble(`Band\nnumber` = 1:5,
         `Band\nname` = c("blue (b)", "green (g)", "red (r)", "near infrared (nir)", "red edge (re)"),
         `Center\nwavelength` = c(475, 560, 668, 840, 717),
         `Band\nwidth` = c(20, 20, 10, 40, 10),
         `Wavelength\nrange` = c("465-485", "550-570", "663-673", "820-860", "712-722"),
         `Panel\nreflectance` = c(0.64, 0.64, 0.64, 0.60, 0.63))

pandoc.table(rededge_print, 
             split.tables = Inf,
             caption = table_nums(name = "table-rededge-specs"),
             keep.line.breaks = TRUE)
```

### Flight protocol

Image capture was conducted as close to solar noon as possible to minimize shadow effects (varying primarily due to site accessibility; always within 4 hours, usually within 2 hours).
Prior to the aerial survey, two strips of bright orange drop cloth (~100cm x 15cm) were positioned as an "X" over the permanent monuments marking the center of the 5 field plots from @fettig2019.

For each of the 32 sites (containing 5 plots each), we captured imagery over the surrounding ~40 hectares of forested area using north-south aerial transects.
For three sites, we surveyed less surrounding area in order to maintain visual and radio communication with the aircraft during flight which can be obstructed by rolling terrain or non-centrally available takeoff locations.

We preprogrammed aerial transects using Map Pilot for DJI on iOS flight software (hereafter Map Pilot) [@dronesmadeeasy2018].
Using the Map Pilot software, we included an altitude adjustment along each aerial transect using a 1-arc-second digital elevation model [@farr2007] such that the aircraft's altitude remained approximately constant at 120 meters above ground level in order to maintain consistent ground sampling distance (centimeters on the ground per pixel) in the imagery.
Ground sampling distance was approximately 5 cm/px for the Zenmuse X3 RGB camera and approximately 8 cm/px for the RedEdge3 multispectral camera.
For this analysis, we dropped 4 sites whose imagery was of insufficient quality to process.

Structure from motion (SfM) processing requires highly overlapping images, especially in densely vegetated areas [@frey2018].
We planned transects with 90% forward overlap and 90% side overlap at 100 meters below the lens.
Thus, with flights being at 120 meters above ground level, we achieved slightly higher than 90/90% overlap for objects under 20 meters tall (91.6/91.6% overlap at the ground).
Overlap values were based on focal length (3.6mm), sensor width (6.2mm), and image dimension (4000x3000 pixels) parameters of the Zenmuse X3 camera.
Images were captured at a constant rate of 1 image every 2 seconds for both cameras.
A forward overlap of 90% at 100 meters translates to a flight speed of approximately 6.45 m/s and a side overlap of 90% at 100 meters translates to transects approximately 17.2 meters apart.
The RedEdge3 camera has a different focal length (5.4mm), sensor width (4.8mm), and image dimension (1280x960 pixels), which translates to image overlap of 80.7/80.7 % at 100m below the lens and 83.9/83.9 % at ground level.
Approximately 1900 photos were captured over each 40 hectare survey area for each camera.

### Structure from Motion (SfM) processing

We used structure from motion (SfM) to generate dense point clouds (`r fig_nums(name = "fig-dense-point-cloud", display = "cite")`), digital surface models (`r fig_nums(name = "fig-dsm", display = "cite")`), and orthorectified reflectance maps (`r fig_nums(name = "fig-ortho", display = "cite")`) for each field site [@frey2018].
We used Pix4Dmapper Cloud to process imagery using parameters ideal for images of a densely vegetated area taken by a multispectral camera.
For 29 sites, we processed the RedEdge3 multispectral imagery alone.
For three sites, we processed the RGB and the multispectral imagery in the same project to enhance the point density of the resulting point cloud.
All SfM projects resulted in a single processing "block," indicating that all images in the project were optimized and processed together.


```{r}
fig_nums(name = "fig-dense-point-cloud", "A dense point cloud representing ~40 hectares of forest is generated using Structure from Motion (SfM) processing of ~1900 images.
The dense point cloud z- position represents the ground elevation plus the vegetation height.")
```

![`r fig_nums(name = "fig-dense-point-cloud")`](../../figures/L1_eldo_3k_3_point-cloud_rgb-cloudcompare.png)

```{r}
fig_nums(name = "fig-dsm", "The digital surface model (DSM) is a 2-dimensional representation of the dense point cloud generated using structure from motion (SfM) processing.
The DSM represents the ground elevation plus the vegetation height.")
```

![`r fig_nums(name = "fig-dsm")`](../../figures/L1_eldo_3k_3_dsm.png)


```{r}
fig_nums(name = "fig-ortho", "The orthomosaic for each of the 32 sites is generated with the Structure from Motion (SfM) processing, showing a top-down view of the whole survey area such that distances between objects in the scene are preserved and can be measured.
Depicted is an example red-green-blue orthomosaic for one of the 32 sites covering approximately 40 hectares.
The resolution of the original orthophoto is approximately 8cm per pixel, and has been considerably coarsened in this depiction.")
```

![`r fig_nums(name = "fig-ortho")`](../../figures/L1_eldo_3k_3_ortho_rgb.png)

### Creating canopy height models

```{r}
fig_nums(name = "fig-dtm", "The digital terrain model (DTM) is generated by processing the dense point cloud using the cloth simulation filter algorithm [@zhang2016], which classifies points as 'ground' or 'not-ground' and then interpolates the 'ground' elevation using Delaunay triangulation for the rest of the dense point cloud footprint.
The DTM represents the ground elevation without any vegetation.")
```

![`r fig_nums(name = "fig-dtm")`](../../figures/L2_eldo_3k_3_dtm.png)

```{r}
fig_nums(name = "fig-chm", "The canopy height model (CHM) is generated by subtracting the digital terrain model from the digital surface model.
The CHM represents the height of all of the elevation above ground level.")
```

![`r fig_nums(name = "fig-chm")`](../../figures/L2_eldo_3k_3_chm.png)

We classified each survey area's dense point cloud into "ground" and "non-ground" points using a cloth simulation filter algorithm [@zhang2016] implemented in the `lidR` [@roussel2019] package.
We rasterized the ground points using the `raster` package [@hijmans2019] to create a digital terrain model (`r fig_nums(name = "fig-dtm", display = "cite")`) representing the ground underneath the vegetation at 1 meter resolution.
We created a canopy height model (`r fig_nums(name = "fig-chm", display = "cite")`) by subtracting the digital terrain model from the digital surface model created in Pix4Dmapper.

### Tree detection

We tested a total of `r nrow(algorithm_summary)` automatic tree detection algorithms and a total of `r sum(algorithm_summary$n)` parameter sets on the canopy height model or the dense point cloud to locate trees within each site (`r table_nums(name = "table-algorithm-deets", display = "cite")`).
We used `r algorithm_summary %>% dplyr::filter(algorithm == "vwf") %>% pull(n)` parameter sets of a variable window filter using the `vwf()` function in the `ForestTools` [@plowright2018] `R` package, including the default `winFun` parameter for the `vwf()` function as well as the "pines" and "combined" functions from @popescu2004 as the `winFun` parameter.
We used `r algorithm_summary %>% dplyr::filter(algorithm == "localMaxima") %>% pull(n)` parameter sets of a local maximum filter implemented in `lidR`.
We used `r algorithm_summary %>% dplyr::filter(algorithm == "li2012") %>% pull(n)` parameter sets of the algorithm from @li2012, which operates on the original point cloud.
These parameter sets included those from @shin2018 and @jakubowski2013.
We used `r algorithm_summary %>% dplyr::filter(algorithm == "watershed") %>% pull(n)` parameter sets of the `watershed` algorithm implemented in `lidR`, which is a wrapper for a function in the `EBImage` package [@pau2010].
We used `r algorithm_summary %>% dplyr::filter(algorithm == "ptrees") %>% pull(n)` parameter sets of `ptrees` [@vega2014] implemented in `lidR` [@roussel2019] and `lidRplugins` [@roussel2019a] and which operates on the raw point cloud, without first normalizing it to height above ground level (i.e., subtracting the ground elevation from the dense point cloud).
We used the default parameter set of the `multichm` [@eysn2015] algorithm implemented in `lidR` [@roussel2019] and `lidRplugins` [@roussel2019a].
Finally, we used `r algorithm_summary %>% dplyr::filter(algorithm == "lmfx") %>% pull(n)` parameter sets of the experimental algorithm `lmfx` [@roussel2019a].

```{r}
table_nums(name = "table-algorithm-deets", "Algorithm name, number of parameter sets tested for each algorithm, and references.")
```

```{r algorithm_summary_print, echo = FALSE, include = TRUE, results = 'asis'}
algorithm_summary_print <-
  algorithm_summary %>% 
  dplyr::rename(`Parameter sets\ntested` = n,
                Algorithm = algorithm) %>%
  dplyr::mutate(`Reference(s)` = c("@li2012; @jakubowski2013; @shin2018", "@roussel2019a", "@roussel2019", "@eysn2015", "@vega2014", "@plowright2018", "@pau2010"))

pandoc.table(algorithm_summary_print, 
             split.tables = Inf,
             caption = table_nums(name = "table-algorithm-deets"),
             keep.line.breaks = TRUE)
```

### Map ground data

Each orthorectified reflectance map was inspected to locate the 5 orange "X"s marking the center of the field plots (`r fig_nums(name = "fig-ortho", display = "cite")`), though some plot centers were obscured due to dense interlocking tree crowns or because a plot center was located directly under a single tree crown.
We were able to locate 110 out of 180 field plots and were then able to use these plots for validation of automated tree detection algorithms.
We used the `sf` package [@pebesma2019] to convert distance-from-center and azimuth measurements of each tree in the ground plots to an x-y position on the SfM-derived reflectance map using the x-y position of the orange X visible in the reflectance map as the center.

### Correspondence of automatic tree detection with ground data

We calculated 7 forest structure metrics for each field plot using the ground data collected by @fettig2019: total number of trees, number of trees greater than 15 meters, mean height of trees, 25^th^ percentile tree height, 75^th^ percentile tree height, mean distance to nearest tree neighbor, mean distance to 2^nd^ nearest neighbor.

For each tree detection algorithm and parameter set described above, we calculated the same set of 7 structure metrics within the footprint of the validation field plots.
We calculated the Pearson's correlation and root mean square error (RMSE) between the ground data and the aerial data for each of the 7 structure metrics for each of the `r sum(algorithm_summary$n)` automatic tree detection algorithms/parameter sets.

For each algorithm and parameter set, we calculated its performance relative to other algorithms as whether its Pearson's correlation was within 5% of the highest Pearson's correlation as well as whether its RMSE was within 5% of the lowest RMSE.
For each algorithm/parameter set, we summed the number of forest structure metrics for which it reached these 5% thresholds.
For automatically detecting trees across the whole study, we selected the algorithm/parameter set that performed well across the most number of forest metrics (`r fig_nums(name = "fig-tree-locations", display = "cite")`).

```{r}
fig_nums(name = "fig-tree-locations", "Tree locations are detected using the `lmfx` [@roussel2019] treetop detection algorithm on the dense point cloud.")
```

![`r fig_nums(name = "fig-tree-locations")`](../../figures/L3a_eldo_3k_3_ttops_cropped.png)


### Segmentation of crowns

```{r}
fig_nums(name = "fig-crown-segmentation", "Individual crowns are delineated using a marker controlled watershed segmentation algorithm [@meyer1990; @plowright2018] on the canopy height model (CHM) using the detected tree locations as a priority map.
If the algorithm failed to delineate a crown for a tree that was identified in the tree detection step, a circular crown with a 0.5m buffer centered on point location of the detected tree was added as a crown.")
```

![`r fig_nums(name = "fig-crown-segmentation")`](../../figures/L3a_eldo_3k_3_crowns_cropped.png)

We delineated individual tree crowns with a marker controlled watershed segmentation algorithm [@meyer1990] using the detected treetops as markers implemented in the `ForestTools` package [@plowright2018].
If the automatic segmentation algorithm failed to generate a crown segment for a detected tree (e.g., often snags with a very small crown footprint), a circular crown was generated with a radius of 0.5 meters.
If the segmentation generated multiple polygons for a single detected tree, only the polygon containing the detected tree was retained (`r fig_nums(name = "fig-crown-segmentation", display = "cite")`).
Image overlap decreases near the edges of the overall flight path, which reduces the quality of the SfM processing in those areas.
Thus, we excluded segmented crowns within 35 meters of the edge of the survey area.
Given the narrower field of view of the RedEdge3 multispectral camera versus the X3 RGB camera whose optical parameters were used to define the ~40 hectare survey area around each site, as well as the 35 meter additional buffering, the survey area at each site was approximately 30 hectares (`r table_nums(name = "table-site-deets", display = "cite")`).

We used the `velox` package [@hunziker2017] to extract all the pixel values from the orthorectified reflectance map for each of the 5 narrow bands within each segmented crown polygon.
Per pixel, we additionally calculated the normalized difference vegetation index (NDVI; @rouse1973), the normalized difference red edge (NDRE; @gitelson1994), the red-green index (RGI; @coops2006), the red edge chlorophyll index (CI~red~ ~edge~; @clevers2013), and the green chlorophyll index (CI~green~; @clevers2013).
For each crown polygon, we calculated the mean value for each raw and derived reflectance band (5 raw; 5 derived).

### Classification of trees

```{r}
fig_nums(name = "fig-live-dead-classification", "Each tree is classified as live or dead by extracting the pixel values from the 5 narrow bands of the Rededge3 camera (and 5 derived bands-- see methods) in the orthomosaic within each segmented tree crown of the detected trees, taking their mean value, and using those means to predict live/dead status with a boosted logistic regression previously trained on a hand-classified set of segmented crowns from across the study area.")
```

![`r fig_nums(name = "fig-live-dead-classification")`](../../figures/L3b_eldo_3k_3_live_dead.png)

```{r}
fig_nums(name = "fig-host-non-host", "For each live tree, we classified its species using the same means of extracted pixel values across the 5 Rededge3 narrow bands (and 5 derived bands) as predictors in a regularized discriminant analysis previously trained on a hand-classified set of segmented crowns from across the study area.")
```

![`r fig_nums(name = "fig-host-non-host")`](../../figures/L3b_eldo_3k_3_host_nonhost.png)

We overlaid the segmented crowns on the reflectance maps from `r length(unique(hand_classified_crowns$site))` sites spanning the latitudinal and elevation gradient in the study.
Using QGIS, we hand classified `r nrow(hand_classified_crowns)` trees as live/dead (`r fig_nums(name = "fig-live-dead-classification", display = "cite")`) and as one of 5 dominant species in the study area (*Pinus ponderosa*, *Pinus lambertiana*, *Abies concolor*, *Calocedrus decurrens*, or *Quercus kelloggi*) using the mapped ground data as a guide.
We treated all trees classified as ponderosa pine as a "host" tree and all other species as "non-host" trees (`r fig_nums(name = "fig-host-non-host", display = "cite")`).

We used all 10 mean values of the reflectance bands for each tree crown polygon to predict whether the hand classified trees were alive or dead using a boosted logistic regression model implemented in the `caret` package (accuracy of live/dead classification on a withheld test dataset: `r round(classifier_stats[classifier_stats$type == "live/dead", "accuracy"] %>% pull() * 100, 1)`%) [@kuhn2008].
For just the living trees, we similarly used all 10 reflectance values to predict the tree species using regularized discriminant analysis implemented in the `caret` package (accuracy of species classification on a withheld testing dataset: `r round(classifier_stats[classifier_stats$type == "species", "accuracy"] %>% pull() * 100, 1)`%; accuracy of WPB host/non-WPB-host (i.e., ponderosa pine versus other tree species) on a withheld testing dataset: `r round(classifier_stats[classifier_stats$type == "host/non-host", "accuracy"] %>% pull() * 100, 1)`%).

Finally, we used these models to classify all tree crowns in the data set as alive or dead as well as the species of living trees.

### Allometric scaling of height to quadratic mean diameter

We converted the height of each tree determined using the canopy height model to its diameter at breast height, 1.37m (DBH).
Using the tree height and DBH ground data from @fettig2019, we fit a simple linear regression to predict DBH from height for each of the 5 dominant species.
Using the model-classified tree species of each segmented tree, we used the corresponding linear relationship for that species to estimate the DBH given the tree's height.
We then calculated the quadratic mean diameter for each 20m x 20m cell as the square root of the average squared diameter of trees within the cell.

### Note on assumptions about dead trees

For the purposes of this study, we assumed that all dead trees were ponderosa pine and were thus host trees for the western pine beetle.
This is a reasonably good assumption for our study area, given that @fettig2019 found that `r pipo_pct_of_all_dead`% of the dead trees in the coincident ground plots were ponderosa pine.
The species contributing to the next highest proportion of dead trees was incense cedar which represented `r cade_pct_of_all_dead`% of the dead trees in the ground plots.
Incense cedar is not a potential host of the western pine beetle, and different forest structure/environment conditions can dictate the dynamic between forest insects and their host tree species [@stephenson2019].
While the detected mortality is most likely to be ponderosa pine, it is critical to interpret our results with this known limitation in mind.

### Rasterizing individual tree data

```{r}
fig_nums(name = "fig-rasterized-prop-dead", "We rasterized the individual tree data by aggregating values to 20m x 20m cells.
This example shows the proportion of dead trees per cell for the same example site as in the previous figures.")
```

![`r fig_nums(name = "fig-rasterized-prop-dead")`](../../figures/L4_eldo_3k_3_prop-dead-rasterized.png)

Because the tree detection algorithms were validated against ground data at the plot level, we rasterized the classified trees at a spatial resolution similar to that of the ground plots (`r fig_nums(name = "fig-rasterized-prop-dead", display = "cite")`).
That is, we rasterized the individual tree data to 20m x 20m pixels equaling 400 m^2^, and the circular ground plots with 11.35m radius covered 404 m^2^.
In each raster cell, we calculated the: number of live trees, number of dead trees, number of ponderosa pine trees, total number of trees (of all species, including ponderosa pine), quadratic mean diameter (QMD) of ponderosa pine trees, and QMD of all trees of any species (overall QMD).
We converted the count of ponderosa pine trees and the total tree count to a density measurement of trees per hectare (tpha) by multiplying the counts in each 20m x 20m cell by `r 10000/400` to create a "host density" and an "overall density" variable per cell.

```{r}
fig_nums(name = "fig-height-mortality-by-data-source", "The relationship between mean host height and the proportion of host mortality based on the data source. Field plot data come from @fettig2019, drone data over field plots comes from this study, but with trees subsetted to only those identified within the ground footprints of the field plots of @fettig2019, and drone data randomly selected at each site come from this study but are randomly selected 20 x 20 m cells (5 from each site) from the Level 4 product. The tree height/mortality relationship appears similar for trees in the coincident field plots (both field-derived and drone-derived tree measurements), while the drone data representing the broader context around the coincident field plots show a dramatically different relationship.")
```

![`r fig_nums(name = "fig-height-mortality-by-data-source")`](../../figures/supplemental-figure_height-mortality-relationship-depends-on-data-source.png)

```{r}
table_nums(name = "table-site-deets", "Site characteristics for each of the 32 sites.
The site name consists of the forest name, elevation band, and rep separated by an underscore.
The Eldorado National Forest is 'eldo', the Stanislaus National Forest is 'stan', the Sierra National Forest is 'sier', and the Sequoia National Forest is 'sequ'.
The elevation band represents the lower bounds of the 305 meter (1000 foot) elevation bands in feet.
Thus '3k' implies that site was located between 3,000 and 4,000 feet (914-1219 meters).
Aerially detected mortality and density of the whole site is presented along with the mortality and density calculated from the ground data (aerial / ground).
The density is measured in trees per hectare (tpha).")
```

```{r site_characteristics_read_file}
site_characteristics <- read_csv(here::here("analyses/analyses_output/summarized-non-spatial-site-data.csv"))

site_characteristics <- 
  site_characteristics %>% 
  dplyr::mutate(ground_tpha_dead = ground_prop_mortality * ground_tpha_total,
                air_tpha_dead = air_prop_mortality * air_tpha_total) %>% 
  dplyr::mutate(`% tree mortality\n(aerial/ground)` = paste(sprintf("%0.0f", air_prop_mortality * 100), 
                                                            sprintf("%0.0f", ground_prop_mortality * 100), sep = "/"),
                `Mortality density\n(tpha; aerial/ground)` = paste(sprintf("%0.0f", air_tpha_dead), 
                                                                   sprintf("%0.0f", ground_tpha_dead), sep = "/"),
                `Overall density\n(tpha; aerial/ground)` = paste(sprintf("%0.0f", air_tpha_total), 
                                                                 sprintf("%0.0f", ground_tpha_total), sep = "/")) %>% 
  dplyr::rename(`CWD\n(mm)` = site_cwd,
                `CWD\n(z-score)` = site_cwd_zscore,
                `Survey area\n(ha)` = buffered_survey_area,
                Site = site) %>% 
  tidyr::separate(Site, into = c("Forest", "Elevation band", "Rep"), remove = FALSE) %>% 
  dplyr::mutate(Forest = case_when(Forest == "eldo" ~ "Eldorado",
                                   Forest == "stan" ~ "Stanislaus",
                                   Forest == "sier" ~ "Sierra",
                                   Forest == "sequ" ~ "Sequoia")) %>% 
  dplyr::mutate(Forest = factor(Forest, levels = c("Eldorado", "Stanislaus", "Sierra", "Sequoia"))) %>% 
  dplyr::arrange(Forest, `Elevation band`, Rep)

```

```{r site_characteristics_by_site, echo = FALSE, include = TRUE, results = 'asis'}
 site_characteristics_by_site <-
  site_characteristics %>% 
  dplyr::select(Site, 
                `CWD\n(mm)`, 
                `CWD\n(z-score)`, 
                `Survey area\n(ha)`, 
                `Overall density\n(tpha; aerial/ground)`, 
                `Mortality density\n(tpha; aerial/ground)`, 
                `% tree mortality\n(aerial/ground)`)

pandoc.table(site_characteristics_by_site, 
             digits = c(10, 3, 3, 4, 10, 10, 10), 
             split.tables = Inf,
             caption = table_nums(name = "table-site-deets"),
             keep.line.breaks = TRUE)
```



# References